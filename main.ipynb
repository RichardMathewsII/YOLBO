{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RichardMathewsII/BODnet/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOSHqMT5uJzp",
        "colab_type": "text"
      },
      "source": [
        "## Load necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RxJ58cFy0ys",
        "colab_type": "code",
        "outputId": "28d5cadc-5550-4b58-f90a-aad94cee0f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "!git clone https://github.com/RichardMathewsII/BODnet\n",
        "# !git clone https://github.com/fizyr/keras-retinanet.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BODnet'...\n",
            "remote: Enumerating objects: 5593, done.\u001b[K\n",
            "remote: Counting objects: 100% (5593/5593), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1567/1567), done.\u001b[K\n",
            "remote: Total 5593 (delta 3981), reused 5589 (delta 3980), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (5593/5593), 8.68 MiB | 2.57 MiB/s, done.\n",
            "Resolving deltas: 100% (3981/3981), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9--7Uh8-keH",
        "colab_type": "code",
        "outputId": "53ca422f-0751-4816-bacb-53bb553cd4bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/BODnet/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BODnet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ajkaA4W-sAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d8759f93-e66b-4a60-becf-cbe7010a8d70"
      },
      "source": [
        "# requirement already satisfied\n",
        "!pip install numpy\n",
        "!pip install tensorflow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.2)\n",
            "Requirement already satisfied: tensorflow in /tensorflow-1.15.0/python3.6 (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.0/python3.6 (from tensorflow) (1.15.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.0/python3.6 (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.24.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (46.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykzwREJm--si",
        "colab_type": "code",
        "outputId": "c43d80f4-997b-45b3-b557-d1a08f581e0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "cythoning keras_retinanet/utils/compute_overlap.pyx to keras_retinanet/utils/compute_overlap.c\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/BODnet/keras_retinanet/utils/compute_overlap.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'keras_retinanet.utils.compute_overlap' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/keras_retinanet\n",
            "creating build/temp.linux-x86_64-3.6/keras_retinanet/utils\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -c keras_retinanet/utils/compute_overlap.c -o build/temp.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kkeras_retinanet/utils/compute_overlap.c:598\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/keras_retinanet\n",
            "creating build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.o -o build/lib.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.cpython-36m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.cpython-36m-x86_64-linux-gnu.so -> keras_retinanet/utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNlOpr4XA_G4",
        "colab_type": "code",
        "outputId": "bbec76ad-a5d2-49b7-eb03-e84597cd772b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "# done\n",
        "import keras"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoxI4F_PzwV9",
        "colab_type": "code",
        "outputId": "eb4a9e3b-e2b2-4a80-fdf8-e4c9096ce5e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "# import python modules from keras_retinanet\n",
        "import sys\n",
        "sys.path.insert(0, '/content/BODnet')\n",
        "\n",
        "# done\n",
        "!pip install keras_resnet\n",
        "\n",
        "# done\n",
        "# import keras_retinanet\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "from keras_retinanet.utils.gpu import setup_gpu"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_resnet in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from keras_resnet) (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.4->keras_resnet) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.4->keras_resnet) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.4->keras_resnet) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.4->keras_resnet) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.4->keras_resnet) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.4->keras_resnet) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.4->keras_resnet) (1.18.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo1TsK4-uJzx",
        "colab_type": "code",
        "outputId": "ad02a6e2-4eae-4aef-f8df-06bdc3f71238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# show images inline\n",
        "%matplotlib inline\n",
        "\n",
        "# automatically reload modules when they have changed\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import miscellaneous modules\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "# set tf backend to allow memory to grow, instead of claiming everything\n",
        "import tensorflow as tf\n",
        "\n",
        "# use this to change which GPU to use\n",
        "gpu = 0\n",
        "\n",
        "# set the modified tf session as backend in keras\n",
        "setup_gpu(gpu)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/BODnet/keras_retinanet/utils/gpu.py:51: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/BODnet/keras_retinanet/utils/gpu.py:53: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/BODnet/keras_retinanet/utils/gpu.py:53: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zgjj5ptRgpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upload data into snapshots and check that it's there\n",
        "os.chdir('/content/BODnet/snapshots')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upk-5QYISzla",
        "colab_type": "code",
        "outputId": "cc8654ae-9307-4475-d26d-20029b3e9eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# check current working directory to confirm it's in snapshots\n",
        "os.getcwd()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/BODnet/snapshots'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnctYHVWuJz8",
        "colab_type": "text"
      },
      "source": [
        "## Load RetinaNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "LAVz22T7uJz-",
        "colab_type": "code",
        "outputId": "e311b589-2d3c-415d-8deb-d076be929db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "source": [
        "# upload trained model into snapshots\n",
        "# adjust this to point to your downloaded/trained model\n",
        "# models can be downloaded here: https://github.com/fizyr/keras-retinanet/releases\n",
        "path = os.getcwd()\n",
        "model_path = os.path.join(path, 'resnet50_coco_best_v2.1.0.h5')\n",
        "\n",
        "# load retinanet model\n",
        "model = models.load_model(model_path, backbone_name='resnet50')\n",
        "# NOTE: OSError: Unable to open file (truncated file: eof = 27262976, sblock->base_addr = 0, stored_eof = 152662144)\n",
        "# This error arises when the file was corrupted upon uploading. Delete the file and reupload.\n",
        "\n",
        "# if the model is not converted to an inference model, use the line below\n",
        "# see: https://github.com/fizyr/keras-retinanet#converting-a-training-model-to-inference-model\n",
        "# model = models.convert_model(model)\n",
        "\n",
        "# print(model.summary())\n",
        "\n",
        "# load label to names mapping for visualization purposes\n",
        "labels_to_names = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/BODnet/keras_retinanet/backend/tensorflow_backend.py:104: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asr_2A9tV0ee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a5b20cba-be6b-4a90-9a44-9307e7cc0381"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resnet50_coco_best_v2.1.0.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EBfW-tJuJ0G",
        "colab_type": "text"
      },
      "source": [
        "## Run detection on example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "-Wc_VK4fuJ0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap = cv2.VideoCapture('/content/BODnet/snapshots/busy_street.mp4')\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error opening video file\")\n",
        "\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "out = cv2.VideoWriter('busy_street_ann2.avi', cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 30, (frame_width, frame_height))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        # load image\n",
        "        # image = read_image_bgr(frame)\n",
        "\n",
        "        # copy to draw on\n",
        "        draw = frame.copy()\n",
        "        draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # preprocess image for network\n",
        "        image = preprocess_image(frame)\n",
        "        image, scale = resize_image(image)\n",
        "\n",
        "        # process image\n",
        "        start = time.time()\n",
        "        boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "        # print(\"processing time: \", time.time() - start)\n",
        "\n",
        "        # correct for image scale\n",
        "        boxes /= scale\n",
        "\n",
        "        # visualize detections\n",
        "        for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "            # scores are sorted so we can break\n",
        "            if score < 0.5:\n",
        "                break\n",
        "        \n",
        "            color = label_color(label)\n",
        "    \n",
        "            b = box.astype(int)\n",
        "            draw_box(draw, b, color=color)\n",
        "    \n",
        "            b = np.array(box).astype(int)\n",
        "            # plt.text(b[0], b[1], s=labels_to_names[label], fontsize = 12, color='white', verticalalignment='top')\n",
        "            # caption = \"{} {:10.5f}\".format(labels_to_names[label], score)\n",
        "            # draw_caption(draw, b, caption)\n",
        "            cv2.putText(draw, labels_to_names[label], (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 2)\n",
        "            cv2.putText(draw, labels_to_names[label], (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 255, 255), 1)\n",
        "        out.write(draw)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4KVgXs7BZLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import datetime\n",
        "import matplotlib.patches as patches\n",
        "import random\n",
        "img_size = 416\n",
        "# load image and get detections\n",
        "img_path = \"test_img.jpg\"\n",
        "prev_time = time.time()\n",
        "img = Image.open(img_path)\n",
        "boxes, scores, labels = model.predict_on_batch(np.expand_dims(img, axis=0))\n",
        "inference_time = datetime.timedelta(seconds=time.time() - prev_time)\n",
        "print ('Inference Time: %s' % (inference_time))\n",
        "# Get bounding-box colors\n",
        "cmap = plt.get_cmap('tab20b')\n",
        "colors = [cmap(i) for i in np.linspace(0, 1, 20)]\n",
        "unique_labels = np.unique(labels)\n",
        "n_cls_preds = len(unique_labels)\n",
        "# bbox_colors = random.sample(colors, n_cls_preds)\n",
        "\n",
        "img = np.array(img)\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(1, figsize=(12,9))\n",
        "ax.imshow(img)\n",
        "pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
        "pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
        "unpad_h = img_size - pad_y\n",
        "unpad_w = img_size - pad_x\n",
        "if scores is not None:\n",
        "    # browse detections and draw bounding boxes\n",
        "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "        if score < 0.5:\n",
        "          break\n",
        "        b = box.astype(int)\n",
        "        b = np.array(box).astype(int)\n",
        "        x1, y1, x2, y2 = b[0], b[1], b[2], b[3]\n",
        "        box_h = ((y2 - y1) / unpad_h) * img.shape[0]\n",
        "        box_w = ((x2 - x1) / unpad_w) * img.shape[1]\n",
        "        y1 = ((y1 - pad_y // 2) / unpad_h) * img.shape[0]\n",
        "        x1 = ((x1 - pad_x // 2) / unpad_w) * img.shape[1]\n",
        "        # color = bbox_colors[int(np.where(\n",
        "        #     unique_labels == int(label))[0])]\n",
        "        bbox = patches.Rectangle((x1, y1), box_w, box_h,\n",
        "             linewidth=2, edgecolor=(0.1, 0.2, 0.5), facecolor='none')\n",
        "        ax.add_patch(bbox)\n",
        "        plt.text(x1, y1, s=labels_to_names[label], \n",
        "                color='white', verticalalignment='top',\n",
        "                bbox={'color': (0.1, 0.2, 0.5), 'pad': 0})\n",
        "plt.axis('off')\n",
        "# save image\n",
        "# plt.savefig(img_path.replace(\".jpg\", \"-det.jpg\"),        \n",
        "#                  bbox_inches='tight', pad_inches=0.0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeBanYEduJ0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import colorsys\n",
        "import random\n",
        "N = len(labels_to_names)\n",
        "HSV_tuples = [(x*1.0/N, 0.5, 0.5) for x in range(N)]\n",
        "RGB_tuples = list(map(lambda x: tuple(255*np.array(colorsys.hsv_to_rgb(*x))), HSV_tuples))\n",
        "random.shuffle(RGB_tuples)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNNwJfQLuJ0V",
        "colab_type": "code",
        "outputId": "83860404-2c51-47f4-e808-b50215f7f413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.physical_device_desc for x in local_device_protos if x.device_type == 'GPU']\n",
        "\n",
        "GPU = get_available_gpus()[-1][17:33]\n",
        "print(GPU)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4, pci bu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01cZJwuuamvh",
        "colab_type": "code",
        "outputId": "f80790c1-12cb-4dfb-edcc-e973acaff633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/keras-retinanet/snapshots'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sGd3GgIuJ0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cap = cv2.VideoCapture('/content/keras-retinanet/snapshots/test.mp4')\n",
        "\n",
        "counter = 0\n",
        "sum_time=0\n",
        "while(True):\n",
        "    ret, draw = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    bgr = cv2.cvtColor(draw, cv2.COLOR_RGB2BGR)\n",
        "    \n",
        "    # preprocess image for network\n",
        "    image = preprocess_image(bgr)\n",
        "    image, scale = resize_image(image)\n",
        "\n",
        "    # process image\n",
        "    start = time.time()\n",
        "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "    t = time.time() - start\n",
        "#     print(\"processing time: \", t)\n",
        "\n",
        "    boxes /= scale\n",
        "\n",
        "    # visualize detections\n",
        "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "        if score < 0.5:\n",
        "            continue\n",
        "        color = label_color(label)\n",
        "    \n",
        "        b = box.astype(int)\n",
        "        draw_box(draw, b, color=color)\n",
        "    \n",
        "        # caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "        # draw = draw_caption(draw, b, caption)\n",
        "        # cv2.imwrite('/tmp/img%08d.jpg'%counter,draw)\n",
        "    cv2_imshow(draw)\n",
        "    if cv2.waitKey(1)  & 0xFF == ord('q'):\n",
        "        break\n",
        "    counter=counter+1\n",
        "    sum_time+=t\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTlQTds-uJ0k",
        "colab_type": "code",
        "outputId": "35c54b26-b9f7-498f-a621-f6d7c7ccfc3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "detections.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}